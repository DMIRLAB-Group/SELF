{
    "collab_server" : "",
    "contents" : "score_ml_cd<-function(G,D,bw,nrounds,\n                      gamma,score_type,booster,...){\n  NodeScore<-rep(0,ncol(G))\n  NodeScore<-updateScore_ml_cd(G,D,NodeScore,1:ncol(G),bw =bw,nrounds=nrounds,\n                               gamma=gamma,score_type=score_type,booster=booster,...)\n  return(NodeScore)\n}\nupdateScore_ml_cd<-function(G,D,NodeScore,nodes,score_type=\"bic\",bw =\"nrd0\",booster=\"gbtree\",gamma=10,nrounds=30,...){\n  Vn<-ncol(G)\n  Dn<-nrow(D)\n  bicterm=log(Dn)/Dn/2\n  for(i in nodes){\n    pa<-parents(G,i)\n    if(length(pa)==0){\n      N<-D[,i]\n      #N<-scale(N)\n      if(is.factor(D[,i])){\n        si=length(unique(D[,i]))\n        d=si-1\n        eta=unlist(table(N)/length(N))\n        if(score_type==\"log\"){\n          NodeScore[i]<-sum(eta*log(eta)) #log\n        }else if(score_type==\"bic\"){\n          NodeScore[i]<-sum(eta*log(eta))-d*bicterm #bic\n        }else if(score_type==\"aic\"){\n          NodeScore[i]<-sum(eta*log(eta))-d/Dn #aic\n        }\n        next\n      }else{\n        if(score_type==\"log\"){\n          f <- stats::approxfun(stats::density(N,bw=bw,from=min(N),to=max(N)))\n          NodeScore[i]<-sum(log(f(N)))/Dn\n        }else if(score_type==\"bic\"){\n          f <- stats::approxfun(stats::density(N,bw=bw,from=min(N),to=max(N)))\n          NodeScore[i]<-sum(log(f(N)))/Dn\n        }else if(score_type==\"aic\"){\n          f <- stats::approxfun(stats::density(N,bw=bw,from=min(N),to=max(N)))\n          NodeScore[i]<-sum(log(f(N)))/Dn-1\n        }\n\n        next\n      }\n    }\n    x<-D[,pa,drop=F]\n    y<-D[,i]\n    #x=stats::predict(dummyVars(~.,data=x,fullRank = T),x)\n\n\n    if(is.factor(y)){\n      collevels<-stats::na.omit(levels(y))\n      y<-factor(y,labels=0:(length(levels(y))-1))\n    }\n    x<-apply(x,2,as.numeric)\n    x<-as.matrix(x)\n    #x<-as.data.frame(x)\n    if(is.factor(y)){\n        num_class<-length(unique(y))\n        model<-xgboost(data=x,label=as.integer(y)-1,\n                       objective=\"multi:softmax\",num_class=num_class,verbose=0,\n                       nrounds=nrounds,gamma=gamma,booster=booster,save_period=NULL,...)\n    }else{\n      if(booster==\"lm\"){\n        model<-.lm.fit(x,as.numeric(y))\n      }else {\n        model<-xgboost(data=x,label=as.numeric(y),\n                       verbose=0,nrounds=nrounds,gamma=gamma,booster=booster,save_period=NULL,...)\n      }\n    }\n    #xgb---end\n    if(booster==\"lm\"){\n      y_hat<-x%*%model$coefficients\n    }else{\n      y_hat<-stats::predict(model,x)\n    }\n\n    if(is.factor(y)){\n      N<-as.numeric(y)-as.numeric(y_hat)-1\n    }else{\n      N<-as.numeric(y)-as.numeric(y_hat)\n    }\n    #N=scale(N)\n\n\n\n\n    if(is.factor(y)){\n      pa<-parents(G,i)\n      pa_name<-names(D)[pa]\n      dt<-as.data.table(D)\n      ri<-nrow(dt[,.N,by=pa_name])\n      #ri<-nrow(ddply(D,as.quoted(pa_name),length))\n      si=length(unique(D[,i]))\n      if(length(ri)==0){\n        ri=1\n      }\n      d=ri*(si-1)\n      eta=unlist(table(N)/length(N))\n      if(score_type==\"log\"){\n        NodeScore[i]<-sum(eta*log(eta)) #log\n      }else if(score_type==\"bic\"){\n        NodeScore[i]<-sum(eta*log(eta))-d*bicterm #bic\n      }else if(score_type==\"aic\"){\n        NodeScore[i]<-sum(eta*log(eta))-d/Dn #aic\n      }\n\n    }else{\n      if(booster==\"gbtree\"){\n        dump=xgb.dump(model)\n        d=length(grep(dump,pattern = \"leaf\"))\n        d=d+length(pa) #add new feature for penalty term\n      }else{\n        d=length(pa)+1  #gblinear\n      }\n      if(score_type==\"log\"){\n        f <- stats::approxfun(stats::density(N,bw=bw,from=min(N),to=max(N)))\n        NodeScore[i]<-sum(log(f(N)))/Dn\n      }else if(score_type==\"bic\"){\n        f <- stats::approxfun(stats::density(N,bw=bw,from=min(N),to=max(N)))\n        NodeScore[i]<-sum(log(f(N)))/Dn-d*bicterm\n      }else if(score_type==\"aic\"){\n        f <- stats::approxfun(stats::density(N,bw=bw,from=min(N),to=max(N)))\n        NodeScore[i]<-sum(log(f(N)))/Dn-bicterm\n      }\n\n    }\n  }\n\n  return(NodeScore)\n}\n#' @title Fast Hill-Climbing\n#' @description The function for the causal structure learning.\n#' @param D Input Data,your data require to be numeric or factor.\n#' @param G An initial graph for hill climbing\n#' @param min_increase Minimum score increase\n#' @param score_type Your can choise \"bic\",\"log\",\"aic\" score. Default: bic\n#' @param file Specifies the output folder and its path.\n#' @param verbose Show the progress bar for each iteration.\n#' @param save_model Save the meta data during the iteration so that you can easily restore progress and evaluate the model during iteration.\n#' @param bw the smoothing bandwidth which is the parameter of the function stats::density(Kernel stats::density Estimation)\n#' @param booster Choose the regression method, it could be \"lm\", \"gbtree\" and \"gblinear\". The \"lm\" and \"gblinear\" is the linear regression method and \"gbtree\" is the nonlinear regression method  Default: gbtree\n#' @param gamma minimum loss reduction required to make a further partition on a leaf node of the tree. the larger, the more conservative the algorithm will be.\n#' @param nrounds the max number of iterations for xgboost.\n#' @param ... other parameters for xgboost.see also: help(xgboost)\n#' @return The adjacency matrix of the casual structure.\n#' @export\n#' @examples\n#' #x->y->z\n#' set.seed(0)\n#' x=rnorm(4000)\n#' y=x^2+runif(4000,-1,1)*0.1\n#' z=y^2+runif(4000,-1,1)*0.1\n#' data=data.frame(x,y,z)\n#' fhc(data,gamma=10,booster = \"gbtree\",save_model=FALSE)\n#'\n#' #x->y->z linear data\n#' set.seed(0)\n#' x=rnorm(4000)\n#' y=3*x+runif(4000,-1,1)*0.1\n#' z=3*y+runif(4000,-1,1)*0.1\n#' data=data.frame(x,y,z)\n#' fhc(data,min_increase=0.01,booster = \"lm\",save_model=FALSE)\n#'\n\nfhc<-function(D,G=NULL,min_increase=0,score_type=\"bic\",\n                      file=\"\",verbose=TRUE,save_model=FALSE,\n                      bw =\"nrd0\",booster=\"gbtree\",gamma=10,nrounds=30,...){\n  min_history_diff=0\n  h=5\n  #if(h<2)stop(\"h should be greater than 2\")\n  if(is.null(G)){\n    G=matrix(0,nrow=ncol(D),ncol=ncol(D))\n    initG=G\n  }else{\n    initG<-G\n  }\n  if(ncol(G)!=ncol(D)){\n    stop(\"the number of nodes should be consistent to the data\")\n  }\n  Vn<-ncol(G)\n  Dn<-nrow(D)\n  if(save_model){\n    if(file!=\"\"){\n      if(!file.exists(file)){\n        dir.create(file)\n      }\n      path=paste0(file,\"/\")\n    }else{\n      path=\"\"\n    }\n    t=1\n\n    file<-sprintf(paste0(path,\"GD%s.RData\"),t)\n    while (file.exists(file)){\n      t=t+1\n      file<-sprintf(paste0(path,\"GD%s.RData\"),t)\n    }\n    if(t==1){\n      if(file.exists(paste0(path,\"initResult\"))){\n        load(paste0(path,\"initResult\"))\n      }else{\n        initResult<-list()\n        history_score=rep(0,h)\n        initResult$G<-G\n        initResult$D<-D\n        initResult$NodeScore<-score_ml_cd(G=initResult$G,D=initResult$D,bw =bw,nrounds=nrounds,\n                                          gamma=gamma,score_type=score_type,booster=booster,...)\n        initResult$score<-sum(initResult$NodeScore)\n        if(save_model){\n          save(initResult,file = paste0(path,\"initResult.RData\"))\n        }\n      }\n      t=0\n    }else{\n      t=t-1\n      file<-sprintf(paste0(path,\"GD%s.RData\"),t)\n      load(file)\n      if(h>length(history_score)){\n        history_score<-c(history_score,rep(0,h-length(history_score)))\n      }\n    }\n  }else{\n      initResult<-list()\n      history_score=rep(0,h)\n      initResult$G<-G\n      initResult$D<-D\n      initResult$NodeScore<-score_ml_cd(initResult$G,initResult$D,bw =bw,nrounds=nrounds,\n                                        gamma=gamma,score_type=score_type,booster=booster,...)\n       initResult$score<-sum(initResult$NodeScore)\n    t=0\n  }\n\n  if(!is.matrix(G)){\n    G<-as.matrix(G)\n  }\n  #bestScore=initResult$score\n  bestScore=-Inf\n  result=initResult\n  bestResult=initResult\n\n\n  repeat{\n    oldG<-G\n    bestG<-G\n    GList<-list()\n    for (i in 1:ncol(G)) {\n      for (j in 1:ncol(G)) {\n        if(i!=j){\n          # here i should choose the top ten j for each i in the graph,j the\n          res<-AddDelReverseLine(G,i=i,j=j)\n          GList<-append(GList,res)\n        }\n      }\n    }\n    GList<-unique(GList)\n    # for(i in 1:length(GList)){\n    #   if(all(GList[[i]]==initG)){\n    #     GList[[i]]<-NULL\n    #     break\n    #   }\n    # }\n    if(verbose){\n      pb <- utils::txtProgressBar(0,length(GList),style = 3)\n    }\n    bestIndex=0\n    for(k in seq.int(length.out = length(GList))){\n      if(verbose){\n        #print(sprintf(\"k=%d/%d\",k,length(GList)))\n        #print(bestG)\n        utils::setTxtProgressBar(pb, k)\n      }\n      nodes<-compareG(G,GList[[k]])\n\n      result$G<-GList[[k]]\n      result$NodeScore<-updateScore_ml_cd(GList[[k]],D,initResult$NodeScore,nodes,\n                                          bw =bw,nrounds=nrounds,gamma=gamma,score_type=score_type,\n                                          booster=booster,...)\n\n      #print(result$NodeScore)\n      result$score<-sum(result$NodeScore)\n      score<-result$score\n      if(score>bestScore){\n        bestScore=score\n        bestResult=result\n        bestIndex=k\n        oldG<-bestG\n        bestG<-GList[[k]]\n      }\n    }\n\n    G<-bestG\n    len=length(history_score)\n    history_score[2:len]<-history_score[1:(len-1)]\n    history_score[1]=bestResult$score\n    if(abs(initResult$score-bestResult$score)<min_increase)break\n    if(diff(range(diff(history_score)))<min_history_diff)break\n    initResult<-bestResult\n    if(verbose){\n      print(paste0(c(\"bestscore:\",sum(bestScore))))\n    }\n    if(save_model){\n      t=t+1\n      output<-sprintf(paste0(path,\"GD%s.RData\"),t)\n      save(G,D,initResult,t,history_score,file=output)\n    }\n\n    if(all(oldG==G))break\nprint(G)\n  }\n  return(bestG)\n}\n",
    "created" : 1504234244793.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2194628744",
    "id" : "DB10CB1A",
    "lastKnownWriteTime" : 1504234302,
    "last_content_update" : 1504234302057,
    "path" : "~/zhengproj/R/Project/self/R/fast_hill_climb.R",
    "project_path" : "R/fast_hill_climb.R",
    "properties" : {
        "docOutlineSize" : "63",
        "docOutlineVisible" : "1"
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}